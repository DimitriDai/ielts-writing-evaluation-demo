import streamlit as st
import os
import sys
import json
import docx
import re
import pandas as pd
from docx import Document
from datetime import datetime
from io import BytesIO

# æ·»åŠ æ¨¡å—è·¯å¾„
BASE_DIR = os.path.dirname(__file__)
MODULE_PATH = os.path.join(BASE_DIR, "Wrt_requirements", "modules")
sys.path.append(MODULE_PATH)

from formatter_ai import (
    load_text_from_file,
    guess_task_type,
    get_feedback_from_deepseek,
    save_feedback_to_docx
)
from tokenizer import basic_stats
from vocab_analysis import load_wordlist, analyze_vocab_levels
from coherence_analysis import load_linking_words, analyze_coherence
from scoring_engine import load_scoring_matrix, evaluate_band_scores

# åˆå§‹åŒ–èµ„æºè·¯å¾„
BASE_PATH = os.path.join(BASE_DIR, "Wrt_requirements")
wordlist_path = os.path.join(BASE_PATH, "wordlists")
criteria_path = os.path.join(BASE_PATH, "criteria")

ox3000 = load_wordlist(os.path.join(wordlist_path, "oxford_3000.json"))
c1c2 = load_wordlist(os.path.join(wordlist_path, "oxford5000_c1_c2.json"))
linking_dict = load_linking_words(os.path.join(wordlist_path, "linking_words.json"))
scoring_df = load_scoring_matrix(os.path.join(criteria_path, "scoring_matrix.xlsx"))

st.set_page_config(page_title="é›…æ€ä½œæ–‡è¯„åˆ†ç³»ç»Ÿ", layout="centered")
st.title("ğŸ“„ é›…æ€ä½œæ–‡è‡ªåŠ¨è¯„åˆ†ä¸åé¦ˆç”Ÿæˆ")

uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼ ä¸€ç¯‡æˆ–å¤šç¯‡ä½œæ–‡æ–‡ä»¶ï¼ˆæ”¯æŒ .txt æˆ– .docxï¼‰", 
    type=["txt", "docx"], 
    accept_multiple_files=True
)

if uploaded_files:
    st.info(f"å…±ä¸Šä¼  {len(uploaded_files)} ç¯‡ä½œæ–‡ã€‚è¯·é€ä¸€å¤„ç†å¹¶ä¸‹è½½ğŸ‘‡")

    for idx, uploaded_file in enumerate(uploaded_files):
        with st.expander(f"ğŸ“„ ä½œæ–‡ {idx+1}ï¼š{uploaded_file.name}", expanded=False):
            file_bytes = uploaded_file.read()
            suffix = uploaded_file.name.split(".")[-1]

            if suffix == "txt":
                text = file_bytes.decode("utf-8")
            else:
                doc = Document(BytesIO(file_bytes))
                text = "\n".join([para.text for para in doc.paragraphs if para.text.strip()])

            st.text_area("âœï¸ ä½œæ–‡å†…å®¹é¢„è§ˆ", value=text, height=200, key=f"preview_{idx}")

            if st.button(f"ğŸš€ å¼€å§‹è¯„åˆ†ï¼š{uploaded_file.name}", key=f"process_{idx}"):
                with st.spinner("æ­£åœ¨ç”Ÿæˆåé¦ˆï¼Œè¯·ç¨å€™..."):
                    task_type = guess_task_type(text)
                    basic = basic_stats(text)
                    word_list = basic["word_list"]
                    vocab = analyze_vocab_levels(word_list, ox3000, c1c2)
                    coherence = analyze_coherence(text, linking_dict)
                    metrics = {
                        **basic,
                        **vocab,
                        **coherence,
                        "has_position": "i think" in text.lower() or "i believe" in text.lower()
                    }

                    band_scores = evaluate_band_scores(metrics, scoring_df)

                    feedback_text = get_feedback_from_deepseek(text, st.secrets["DEEPSEEK_API_KEY"], task_type=task_type)

                    output_doc = BytesIO()
                    save_feedback_to_docx(feedback_text, output_doc, task_type, band_scores, original_text=text)
                    output_doc.seek(0)

                    now = datetime.now().strftime("%Y%m%d_%H%M")
                    filename = f"åé¦ˆ_{uploaded_file.name.replace('.txt','').replace('.docx','')}_{now}.docx"

                    st.success(f"âœ… {uploaded_file.name} å¤„ç†å®Œæˆ")
                    st.download_button("ğŸ“¥ ä¸‹è½½åé¦ˆæŠ¥å‘Š", output_doc, file_name=filename, key=f"download_{idx}")

#cd "D:\Python\Code\EduTech\streamlit_wrt_app"   
#streamlit run streamlit_wrt_app.py
